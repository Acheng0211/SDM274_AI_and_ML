{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_feature = 1, epoch = 200, lr = 0.01, tol = None):\n",
    "        self.n_feature = n_feature\n",
    "        self.epoch = epoch\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.W = np.random.rand(n_feature + 1) * 0.5\n",
    "        self.loss = []\n",
    "        self.best_loss = np.inf\n",
    "        self.patience = 10 \n",
    "        self.X_train_bar = []\n",
    "\n",
    "    def _loss(self, y, y_pred):\n",
    "        return -y_pred * y if y_pred * y <0 else 0\n",
    "    \n",
    "    def _gradient(self, x_bar, y, y_pred):\n",
    "        return -y * x_bar if y_pred * y <0 else 0\n",
    "    \n",
    "    def _preprocess_data(self,X):\n",
    "        m, n = X.shape\n",
    "        X_ = np.empty([m, n+1])\n",
    "        X_[:, 0] = 1\n",
    "        X_[:, 1:] = X\n",
    "        return X_\n",
    "    \n",
    "    def sgd_update(self, X, y):\n",
    "        break_out = False\n",
    "        epoch_no_improve = 0\n",
    "\n",
    "        for iter in range(self.epoch):\n",
    "            for i,x in enumerate(X):\n",
    "                y_pred = self._predict(x)\n",
    "                loss = self._loss(y[i], y_pred)\n",
    "                self.loss.append(loss)\n",
    "\n",
    "                if self.tol is not None:\n",
    "                    if loss < self.best_loss - self.tol:\n",
    "                        self.best_loss = loss\n",
    "                        epoch_no_improve = 0\n",
    "                    elif np.abs(loss-self.best_loss) < self.tol:\n",
    "                        epoch_no_improve += 1\n",
    "                        if epoch_no_improve >= self.patience:\n",
    "                            print(f\"Early stopping triggered due to the no improvement in loss\")\n",
    "                            break_out = True\n",
    "                            break\n",
    "                        else:\n",
    "                            epoch_no_improve = 0\n",
    "                            grad = self._gradient(x, y[i], y_pred)\n",
    "                            self.W -= self.lr * grad\n",
    "                if break_out:\n",
    "                    break_out = False\n",
    "                    break\n",
    "\n",
    "\n",
    "    def _sgd_update(self, X, y): #epoch=2750\n",
    "        pred = X @ self.W \n",
    "        i = np.random.randint(0, len(X))\n",
    "        grad = self._gradient(X[i,:][np.newaxis, :], y[i], pred[i])\n",
    "        self.W -= self.lr * grad  # 随机梯度下降更新\n",
    "\n",
    "    def _bgd_update(self, X, y): #lr=1e-6\n",
    "        pred = X @ self.W \n",
    "        grad = self._gradient(X, y, pred)\n",
    "        self.W -= self.lr * grad  # 批量梯度下降更新\n",
    "        \n",
    "    def _mbgd_update(self, X, y): #epoch=10000\n",
    "        pred = self._predict(X)\n",
    "        indices = np.random.choice(y.shape[0], self.batch_size, replace=False)\n",
    "        grad = self._gradient(X[indices], y[indices], pred[indices])\n",
    "        self.W -= self.lr * grad/self.batch_size\n",
    "\n",
    "    def _predict(self, X):\n",
    "        return X @ self.W\n",
    "    \n",
    "    def train(self, X_train, t_train):\n",
    "        X_train_bar = self._preprocess_data(X_train)\n",
    "        self.X_train_bar = X_train_bar\n",
    "        print(X_train_bar,X_train_bar.shape)\n",
    "        self.sgd_update(X_train_bar, t_train)\n",
    "        print(self.W,self.W.shape)\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array([[-2,4],[4,1],[1,6],[2,4],[6,2]])\n",
    "# y_train = np.array([-1,-1,1,1,1])\n",
    "# _,n_feature = X_train.shape\n",
    "# model = Perceptron(n_feature=n_feature, epoch = 200, lr = 0.01, tol = 1e-3)\n",
    "# model.train(X_train,y_train)\n",
    "# print(f\"Learned weights are {model.W}\")\n",
    "# y_pred = np.sign(model._predict(model._preprocess_data(X_train)))\n",
    "# print(f\"Prediced labels are {y_pred}\")\n",
    "\n",
    "# plt.figure()\n",
    "# model.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从wine.data中删除一类样本，并将保留后的两类样本wine_data_filtered作为新的数据集，并以（0.7，0.3）的比例将wine_data_filtered分为training set和test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset class distribution:\n",
      "class_label\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "New dataset class distribution:\n",
      "class_label\n",
      "2    71\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original dataset shape: (178, 14)\n",
      "New dataset shape: (119, 14)\n",
      "Training set shape: (83, 13)\n",
      "Test set shape: (36, 13)\n"
     ]
    }
   ],
   "source": [
    "file_name = 'wine.data'\n",
    "\n",
    "# 读取数据集\n",
    "column_names = ['class_label'] + [f'feature_{i}' for i in range(13)]  \n",
    "wine_data = pd.read_csv(file_name, header=None, names=column_names)\n",
    "\n",
    "# 显示原始数据集的类别分布\n",
    "print(\"Original dataset class distribution:\")\n",
    "print(wine_data['class_label'].value_counts())\n",
    "\n",
    "# 删除 class_label = 1 的所有行\n",
    "wine_data_filtered = wine_data[wine_data['class_label'] != 1]\n",
    "\n",
    "# 显示新数据集的类别分布\n",
    "print(\"\\nNew dataset class distribution:\")\n",
    "print(wine_data_filtered['class_label'].value_counts())\n",
    "\n",
    "# 检查新数据集的形状\n",
    "print(\"\\nOriginal dataset shape:\", wine_data.shape)\n",
    "print(\"New dataset shape:\", wine_data_filtered.shape)\n",
    "\n",
    "# 将数据分为特征和标签\n",
    "X = wine_data_filtered.drop('class_label', axis=1).values\n",
    "y = wine_data_filtered['class_label'].values\n",
    "\n",
    "# 划分训练集和测试集，这里我们按照70%训练集，30%测试集的比例来划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 打印结果以确认划分\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 1.156e+01 2.050e+00 ... 9.300e-01 3.690e+00 4.650e+02]\n",
      " [1.000e+00 1.288e+01 2.990e+00 ... 7.400e-01 1.420e+00 5.300e+02]\n",
      " [1.000e+00 1.334e+01 9.400e-01 ... 1.020e+00 1.930e+00 7.500e+02]\n",
      " ...\n",
      " [1.000e+00 1.279e+01 2.670e+00 ... 4.800e-01 1.470e+00 4.800e+02]\n",
      " [1.000e+00 1.146e+01 3.740e+00 ... 7.500e-01 2.810e+00 5.620e+02]\n",
      " [1.000e+00 1.369e+01 3.260e+00 ... 9.600e-01 1.820e+00 6.800e+02]] (83, 14)\n",
      "[0.274198   0.02478604 0.14223267 0.26355985 0.10623811 0.46264539\n",
      " 0.05351522 0.34587228 0.47592059 0.15589975 0.11943345 0.17453396\n",
      " 0.31608532 0.33624033] (14,)\n",
      "Learned weights are [0.274198   0.02478604 0.14223267 0.26355985 0.10623811 0.46264539\n",
      " 0.05351522 0.34587228 0.47592059 0.15589975 0.11943345 0.17453396\n",
      " 0.31608532 0.33624033]\n",
      "Prediced labels are [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Perceptron(n_feature = X_train.shape[1], epoch = 2000, lr = 1, tol = 1e-3)\n",
    "model.train(X_train,y_train)\n",
    "print(f\"Learned weights are {model.W}\")\n",
    "y_pred = np.sign(model._predict(model.X_train_bar))\n",
    "\n",
    "# y_pred = np.sign(model._predict(model._preprocess_data(X_train)))\n",
    "print(f\"Prediced labels are {y_pred}\")\n",
    "\n",
    "plt.figure()\n",
    "model.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 计算多分类问题的指标\u001b[39;00m\n\u001b[1;32m      4\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm274/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm274/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model._predict(model._preprocess_data(X_test)), axis=1)\n",
    "\n",
    "# 计算多分类问题的指标\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Macro Recall: {recall}\")\n",
    "print(f\"Macro Precision: {precision}\")\n",
    "print(f\"Macro F1 Score: {f1}\")\n",
    "\n",
    "# 计算 Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# 计算 Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# 计算 Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# 计算 F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdm274",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
