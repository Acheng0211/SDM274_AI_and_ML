{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_feature = 1, epoch = 200, lr = 0.01, tol = None):\n",
    "        self.n_feature = n_feature\n",
    "        self.epoch = epoch\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.W = np.random.rand(n_feature + 1) * 0.5\n",
    "        self.loss = []\n",
    "        self.best_loss = np.inf\n",
    "        self.patience = 10 \n",
    "\n",
    "    def _loss(self, y, y_pred):\n",
    "        return -y_pred * y if y_pred * y <0 else 0\n",
    "    \n",
    "    def _gradient(self, x_bar, y, y_pred):\n",
    "        return -y * x_bar if y_pred * y <0 else 0\n",
    "    \n",
    "    def _preprocess_data(self,X):\n",
    "        m, n = X.shape\n",
    "        X_ = np.empty([m, n+1])\n",
    "        X_[:, 0] = 1\n",
    "        X_[:, 1:] = X\n",
    "        return X_\n",
    "    \n",
    "    def sgd_update(self, X, y):\n",
    "        break_out = False\n",
    "        epoch_no_improve = 0\n",
    "\n",
    "        for iter in range(self.epoch):\n",
    "            for i,x in enumerate(X):\n",
    "                y_pred = self._predict(x)\n",
    "                loss = self._loss(y[i], y_pred)\n",
    "                self.loss.append(loss)\n",
    "\n",
    "                if self.tol is not None:\n",
    "                    if loss < self.best_loss - self.tol:\n",
    "                        self.best_loss = loss\n",
    "                        epoch_no_improve = 0\n",
    "                    elif np.abs(loss-self.best_loss) < self.tol:\n",
    "                        epoch_no_improve += 1\n",
    "                        if epoch_no_improve >= self.patience:\n",
    "                            print(f\"Early stopping triggered due to the no improvement in loss\")\n",
    "                            break_out = True\n",
    "                            break\n",
    "                        else:\n",
    "                            epoch_no_improve = 0\n",
    "                            grad = self._gradient(x, y[i], y_pred)\n",
    "                            self.W -= self.lr * grad\n",
    "                if break_out:\n",
    "                    break_out = False\n",
    "                    break\n",
    "\n",
    "\n",
    "    def _sgd_update(self, X, y): #epoch=2750\n",
    "        pred = X @ self.W \n",
    "        i = np.random.randint(0, len(X))\n",
    "        grad = self._gradient(X[i,:][np.newaxis, :], y[i], pred[i])\n",
    "        self.W -= self.lr * grad  # 随机梯度下降更新\n",
    "\n",
    "    def _bgd_update(self, X, y): #lr=1e-6\n",
    "        pred = X @ self.W \n",
    "        grad = self._gradient(X, y, pred)\n",
    "        self.W -= self.lr * grad  # 批量梯度下降更新\n",
    "        \n",
    "    def _mbgd_update(self, X, y): #epoch=10000\n",
    "        pred = self._predict(X)\n",
    "        indices = np.random.choice(y.shape[0], self.batch_size, replace=False)\n",
    "        grad = self._gradient(X[indices], y[indices], pred[indices])\n",
    "        self.W -= self.lr * grad/self.batch_size\n",
    "\n",
    "    def _predict(self, X):\n",
    "        return X @ self.W\n",
    "    \n",
    "    def train(self, X_train, t_train):\n",
    "        X_train_bar = self._preprocess_data(X_train)\n",
    "        print(X_train_bar)\n",
    "        self.sgd_update(X_train_bar, t_train)\n",
    "        print(self.W)\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "[[ 1. -2.  4.]\n",
      " [ 1.  4.  1.]\n",
      " [ 1.  1.  6.]\n",
      " [ 1.  2.  4.]\n",
      " [ 1.  6.  2.]]\n",
      "[0.12252075 0.01806939 0.12043498]\n",
      "Learned weights are [0.12252075 0.01806939 0.12043498]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(X_train,y_train)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearned weights are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mW\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediced labels are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "Cell \u001b[0;32mIn[23], line 72\u001b[0m, in \u001b[0;36mPerceptron._predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)"
     ]
    }
   ],
   "source": [
    "X_train = np.array([[-2,4],[4,1],[1,6],[2,4],[6,2]])\n",
    "y_train = np.array([-1,-1,1,1,1])\n",
    "_,n_feature = X_train.shape\n",
    "print(X_train.shape)\n",
    "model = Perceptron(n_feature=n_feature, epoch = 200, lr = 1, tol = 1e-3)\n",
    "model.train(X_train,y_train)\n",
    "print(f\"Learned weights are {model.W}\")\n",
    "y_pred = np.sign(model._predict(X_train))\n",
    "print(f\"Prediced labels are {y_pred}\")\n",
    "\n",
    "plt.figure()\n",
    "model.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从wine.data中删除一类样本，并将保留后的两类样本wine_data_filtered作为新的数据集，并以（0.7，0.3）的比例将wine_data_filtered分为training set和test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset class distribution:\n",
      "class_label\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "New dataset class distribution:\n",
      "class_label\n",
      "2    71\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original dataset shape: (178, 14)\n",
      "New dataset shape: (119, 14)\n",
      "Training set shape: (83, 13)\n",
      "Test set shape: (36, 13)\n"
     ]
    }
   ],
   "source": [
    "file_name = 'wine.data'\n",
    "\n",
    "# 读取数据集\n",
    "column_names = ['class_label'] + [f'feature_{i}' for i in range(13)]  \n",
    "wine_data = pd.read_csv(file_name, header=None, names=column_names)\n",
    "\n",
    "# 显示原始数据集的类别分布\n",
    "print(\"Original dataset class distribution:\")\n",
    "print(wine_data['class_label'].value_counts())\n",
    "\n",
    "# 删除 class_label = 1 的所有行\n",
    "wine_data_filtered = wine_data[wine_data['class_label'] != 1]\n",
    "\n",
    "# 显示新数据集的类别分布\n",
    "print(\"\\nNew dataset class distribution:\")\n",
    "print(wine_data_filtered['class_label'].value_counts())\n",
    "\n",
    "# 检查新数据集的形状\n",
    "print(\"\\nOriginal dataset shape:\", wine_data.shape)\n",
    "print(\"New dataset shape:\", wine_data_filtered.shape)\n",
    "\n",
    "# 将数据分为特征和标签\n",
    "X = wine_data_filtered.drop('class_label', axis=1).values\n",
    "y = wine_data_filtered['class_label'].values\n",
    "\n",
    "# 划分训练集和测试集，这里我们按照70%训练集，30%测试集的比例来划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 打印结果以确认划分\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 1.156e+01 2.050e+00 ... 9.300e-01 3.690e+00 4.650e+02]\n",
      " [1.000e+00 1.288e+01 2.990e+00 ... 7.400e-01 1.420e+00 5.300e+02]\n",
      " [1.000e+00 1.334e+01 9.400e-01 ... 1.020e+00 1.930e+00 7.500e+02]\n",
      " ...\n",
      " [1.000e+00 1.279e+01 2.670e+00 ... 4.800e-01 1.470e+00 4.800e+02]\n",
      " [1.000e+00 1.146e+01 3.740e+00 ... 7.500e-01 2.810e+00 5.620e+02]\n",
      " [1.000e+00 1.369e+01 3.260e+00 ... 9.600e-01 1.820e+00 6.800e+02]]\n",
      "[0.20028296 0.43858245 0.3648287  0.12489691 0.01798604 0.11843801\n",
      " 0.39803079 0.07355456 0.49625258 0.15115703 0.40840874 0.14676275\n",
      " 0.32333675 0.06706945]\n",
      "Learned weights are [0.20028296 0.43858245 0.3648287  0.12489691 0.01798604 0.11843801\n",
      " 0.39803079 0.07355456 0.49625258 0.15115703 0.40840874 0.14676275\n",
      " 0.32333675 0.06706945]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 14 is different from 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(X_train,y_train)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearned weights are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mW\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediced labels are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "Cell \u001b[0;32mIn[12], line 72\u001b[0m, in \u001b[0;36mPerceptron._predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 14 is different from 13)"
     ]
    }
   ],
   "source": [
    "# model = Perceptron(n_feature = X_train.shape[1], epoch = 2000, lr = 1, tol = 1e-3)\n",
    "# model.train(X_train,y_train)\n",
    "# print(f\"Learned weights are {model.W}\")\n",
    "# y_pred = np.sign(model._predict(X_train))\n",
    "# print(f\"Prediced labels are {y_pred}\")\n",
    "\n",
    "# plt.figure()\n",
    "# model.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdm274",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
