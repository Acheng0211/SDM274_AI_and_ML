{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary parts to train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import hydra.conf\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "from omegaconf import DictConfig\n",
    "import utils\n",
    "from model import LinearRegression, Perceptron, LogisticRegression, MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and hyperparameters configs, split training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(version_base=\"1.3\", config_path=\"./conf\", config_name=\"config_proj_midterm\")\n",
    "def main(cfg: DictConfig):\n",
    "    # Preprocess dataset\n",
    "    dataset_path = cfg.dataset\n",
    "    print(\"If path is existed:\", os.path.exists(dataset_path))\n",
    "    X, y = utils.load_and_process_data(dataset_path, features_to_remove=None) \n",
    "    X_train, X_test, y_train, y_test = utils.split_data(X[:,1:], y, test_size=0.3, val_size=0.2, random_state=42)\n",
    "\n",
    "    if(cfg.wandb_on_off and cfg.name == \"Project_midterm\"):\n",
    "        wandb.init(project=\"Project_midterm\")\n",
    "        \n",
    "    X_train_f = X_train[:,3:]\n",
    "    X_test_f = X_test[:,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "print(\"Linear Regression training\")\n",
    "model_L = LinearRegression(n_feature=X_train_f.shape[1], epoch = cfg.epoch, lr = cfg.lr_linear_regression, batch_size=cfg.batch_size, gd = cfg.gd)\n",
    "model_L.fit(X_train_f, y_train)\n",
    "metrics_L = model_L._evaluate(X_test_f, y_test)\n",
    "print(f\"Linear Regression evaluation: {metrics_L}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron model implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "y_train_P = y_train.copy()\n",
    "y_test_P = y_test.copy()\n",
    "y_train_P[y_train_P == 0] = -1\n",
    "y_test_P[y_test_P == 0] = -1\n",
    "model_P = Perceptron(n_feature=X_train.shape[1], epoch=1000, lr=cfg.lr, tol=cfg.tol, wandb=cfg.wandb_on_off, gd=cfg.gd)\n",
    "model_P.fit(X_train, y_train_P)\n",
    "metrics_P = model_P._evaluate(X_test, y_test_P)\n",
    "print(f\"Perceptron evaluation: {metrics_P}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "print(\"Logistic Regression training\")\n",
    "model_LR = LogisticRegression(n_feature=X_train_f.shape[1], epoch=cfg.epoch, lr=cfg.lr, tol=cfg.tol, wandb=cfg.wandb_on_off, gd=cfg.gd)\n",
    "model_LR.fit(X_train_f, y_train)\n",
    "metrics_LR = model_LR._evaluate(X_test_f, y_test)\n",
    "print(f\"Logistic Regression evaluation: {metrics_LR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "print(\"MLP training\")\n",
    "input_size = X_train_f.shape[1]\n",
    "layers_list = [input_size] + cfg.hidden_layers + [1]\n",
    "model_MLP = MLP(layers_list)\n",
    "model_MLP.train(X_train_f, y_train, cfg.epoch, cfg.lr, cfg.batch_size, cfg.gd)\n",
    "metrics_MLP = model_MLP.evaluate(X_test_f, y_test)\n",
    "print(f\"MLP evaluation with two correlated features: {metrics_MLP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results with all the features using 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression evaluation:{'accuracy': 0.031, 'recall': 0.031, 'precision': 0.000961, 'f1': 0.0018642095053346267}\n",
      "Perceptron evaluation: {'accuracy': 0.031, 'recall': 0.031, 'precision': 0.000961, 'f1': 0.0018642095053346267}\n",
      "Logistic Regression evaluation: {'accuracy': 0.969, 'recall': 0.969, 'precision': 0.9389609999999999, 'f1': 0.9537440325038092} \n",
      "MLP evaluation: {'accuracy': 0.9661, 'recall': 0.9661, 'precision': 0.9338183500000001, 'f1': 0.9495677504357161}\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression evaluation:{'accuracy': 0.031, 'recall': 0.031, 'precision': 0.000961, 'f1': 0.0018642095053346267}\\nPerceptron evaluation: {'accuracy': 0.031, 'recall': 0.031, 'precision': 0.000961, 'f1': 0.0018642095053346267}\\nLogistic Regression evaluation: {'accuracy': 0.969, 'recall': 0.969, 'precision': 0.9389609999999999, 'f1': 0.9537440325038092} \\nMLP evaluation: {'accuracy': 0.9661, 'recall': 0.9661, 'precision': 0.9338183500000001, 'f1': 0.9495677504357161}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using different features to train MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "print(\"MLP training\")\n",
    "input_size = X_train_f.shape[1]\n",
    "layers_list = [input_size] + cfg.hidden_layers + [1]\n",
    "model_MLP = MLP(layers_list)\n",
    "model_MLP.train(X_train_f, y_train, cfg.epoch, cfg.lr, cfg.batch_size, cfg.gd)\n",
    "metrics_MLP = model_MLP.evaluate(X_test_f, y_test)\n",
    "\n",
    "input_size1 = X_train[:,0:3].shape[1]\n",
    "layers_list1 = [input_size1] + cfg.hidden_layers + [1]\n",
    "model_MLP1 = MLP(layers_list1)\n",
    "model_MLP1.train(X_train[:,0:3], y_train, cfg.epoch, cfg.lr, cfg.batch_size, cfg.gd)\n",
    "metrics_MLP1 = model_MLP.evaluate(X_test_f, y_test)\n",
    "\n",
    "input_size2 = X_train.shape[1]\n",
    "layers_list2 = [input_size2] + cfg.hidden_layers + [1]\n",
    "model_MLP2 = MLP(layers_list2)\n",
    "model_MLP2.train(X_train, y_train, cfg.epoch, cfg.lr, cfg.batch_size, cfg.gd)\n",
    "metrics_MLP2 = model_MLP.evaluate(X_test_f, y_test)\n",
    "\n",
    "print(f\"MLP evaluation with two correlated features: {metrics_MLP}\")\n",
    "print(f\"MLP evaluation with another three features: {metrics_MLP1}\")\n",
    "print(f\"MLP evaluation with all features: {metrics_MLP2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results with all the features using MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP evaluation with two correlated features: {'accuracy': 0.9661, 'recall': 0.9661, 'precision': 0.933818350001, 'f1': 0.9495677504357161}\n",
      "MLP evaluation with another three features: {'accuracy': 0.898, 'recall': 0.06557377049180328, 'precision': 0.015810276679841896, 'f1': 0.02547770700636942}\n",
      "MLP evaluation with all features: {'accuracy': 0.961, 'recall': 0.010752688172043012, 'precision': 0.038461538461538464, 'f1': 0.01680672268907563}\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP evaluation with two correlated features: {'accuracy': 0.9661, 'recall': 0.9661, 'precision': 0.933818350001, 'f1': 0.9495677504357161}\\nMLP evaluation with another three features: {'accuracy': 0.898, 'recall': 0.06557377049180328, 'precision': 0.015810276679841896, 'f1': 0.02547770700636942}\\nMLP evaluation with all features: {'accuracy': 0.961, 'recall': 0.010752688172043012, 'precision': 0.038461538461538464, 'f1': 0.01680672268907563}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
